Accuracy on test data is: 83.06




390/390 [==============================] - 17s 44ms/step - loss: 1.8319 - acc: 0.3042 - val_loss: 1.4708 - val_acc: 0.4534
Epoch 2/50
390/390 [==============================] - 8s 21ms/step - loss: 1.3180 - acc: 0.5235 - val_loss: 1.1225 - val_acc: 0.5931
Epoch 3/50
390/390 [==============================] - 8s 21ms/step - loss: 1.1143 - acc: 0.6060 - val_loss: 0.9666 - val_acc: 0.6564
Epoch 4/50
390/390 [==============================] - 8s 21ms/step - loss: 0.9826 - acc: 0.6569 - val_loss: 0.8706 - val_acc: 0.7010
Epoch 5/50
390/390 [==============================] - 8s 21ms/step - loss: 0.8851 - acc: 0.6941 - val_loss: 0.7671 - val_acc: 0.7355
Epoch 6/50
390/390 [==============================] - 8s 21ms/step - loss: 0.7990 - acc: 0.7269 - val_loss: 0.7310 - val_acc: 0.7484
Epoch 7/50
390/390 [==============================] - 8s 21ms/step - loss: 0.7472 - acc: 0.7435 - val_loss: 0.6910 - val_acc: 0.7609
Epoch 8/50
390/390 [==============================] - 8s 21ms/step - loss: 0.6968 - acc: 0.7630 - val_loss: 0.6684 - val_acc: 0.7725
Epoch 9/50
390/390 [==============================] - 8s 21ms/step - loss: 0.6663 - acc: 0.7724 - val_loss: 0.6922 - val_acc: 0.7646
Epoch 10/50
390/390 [==============================] - 8s 21ms/step - loss: 0.6427 - acc: 0.7816 - val_loss: 0.6482 - val_acc: 0.7787
Epoch 11/50
390/390 [==============================] - 8s 21ms/step - loss: 0.6157 - acc: 0.7900 - val_loss: 0.6409 - val_acc: 0.7803
Epoch 12/50
390/390 [==============================] - 8s 21ms/step - loss: 0.5907 - acc: 0.8002 - val_loss: 0.6328 - val_acc: 0.7902
Epoch 13/50
390/390 [==============================] - 8s 21ms/step - loss: 0.5537 - acc: 0.8099 - val_loss: 0.6000 - val_acc: 0.7988
Epoch 14/50
390/390 [==============================] - 8s 21ms/step - loss: 0.5432 - acc: 0.8141 - val_loss: 0.6378 - val_acc: 0.7894
Epoch 15/50
390/390 [==============================] - 8s 21ms/step - loss: 0.5250 - acc: 0.8211 - val_loss: 0.6394 - val_acc: 0.7889
Epoch 16/50
390/390 [==============================] - 8s 21ms/step - loss: 0.5168 - acc: 0.8245 - val_loss: 0.6069 - val_acc: 0.7969
Epoch 17/50
390/390 [==============================] - 8s 20ms/step - loss: 0.5055 - acc: 0.8285 - val_loss: 0.6035 - val_acc: 0.8000
Epoch 18/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4887 - acc: 0.8340 - val_loss: 0.6199 - val_acc: 0.8001
Epoch 19/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4776 - acc: 0.8367 - val_loss: 0.5947 - val_acc: 0.8046
Epoch 20/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4657 - acc: 0.8397 - val_loss: 0.5825 - val_acc: 0.8127
Epoch 21/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4509 - acc: 0.8452 - val_loss: 0.6040 - val_acc: 0.8127
Epoch 22/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4551 - acc: 0.8458 - val_loss: 0.5803 - val_acc: 0.8135
Epoch 23/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4507 - acc: 0.8473 - val_loss: 0.5852 - val_acc: 0.8127
Epoch 24/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4326 - acc: 0.8526 - val_loss: 0.5862 - val_acc: 0.8138
Epoch 25/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4266 - acc: 0.8557 - val_loss: 0.5684 - val_acc: 0.8143
Epoch 26/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4170 - acc: 0.8567 - val_loss: 0.5804 - val_acc: 0.8207
Epoch 27/50
390/390 [==============================] - 8s 20ms/step - loss: 0.4042 - acc: 0.8617 - val_loss: 0.5783 - val_acc: 0.8136
Epoch 28/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3998 - acc: 0.8660 - val_loss: 0.5994 - val_acc: 0.8143
Epoch 29/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3969 - acc: 0.8672 - val_loss: 0.6043 - val_acc: 0.8114
Epoch 30/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3959 - acc: 0.8653 - val_loss: 0.5516 - val_acc: 0.8224
Epoch 31/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3809 - acc: 0.8709 - val_loss: 0.5568 - val_acc: 0.8240
Epoch 32/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3816 - acc: 0.8719 - val_loss: 0.6089 - val_acc: 0.8049
Epoch 33/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3776 - acc: 0.8727 - val_loss: 0.5607 - val_acc: 0.8266
Epoch 34/50
390/390 [==============================] - 8s 20ms/step - loss: 0.3698 - acc: 0.8742 - val_loss: 0.5994 - val_acc: 0.8172
Epoch 35/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3694 - acc: 0.8758 - val_loss: 0.5726 - val_acc: 0.8233
Epoch 36/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3632 - acc: 0.8784 - val_loss: 0.5687 - val_acc: 0.8239
Epoch 37/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3499 - acc: 0.8819 - val_loss: 0.5628 - val_acc: 0.8251
Epoch 38/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3499 - acc: 0.8814 - val_loss: 0.5988 - val_acc: 0.8112
Epoch 39/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3474 - acc: 0.8826 - val_loss: 0.5556 - val_acc: 0.8237
Epoch 40/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3485 - acc: 0.8805 - val_loss: 0.5736 - val_acc: 0.8215
Epoch 41/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3327 - acc: 0.8882 - val_loss: 0.5724 - val_acc: 0.8248
Epoch 42/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3371 - acc: 0.8869 - val_loss: 0.5773 - val_acc: 0.8217
Epoch 43/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3431 - acc: 0.8863 - val_loss: 0.5823 - val_acc: 0.8181
Epoch 44/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3306 - acc: 0.8900 - val_loss: 0.5868 - val_acc: 0.8233
Epoch 45/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3342 - acc: 0.8890 - val_loss: 0.5757 - val_acc: 0.8232
Epoch 46/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3261 - acc: 0.8895 - val_loss: 0.5963 - val_acc: 0.8234
Epoch 47/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3174 - acc: 0.8932 - val_loss: 0.6159 - val_acc: 0.8252
Epoch 48/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3237 - acc: 0.8913 - val_loss: 0.5935 - val_acc: 0.8236
Epoch 49/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3223 - acc: 0.8916 - val_loss: 0.5837 - val_acc: 0.8320
Epoch 50/50
390/390 [==============================] - 8s 21ms/step - loss: 0.3103 - acc: 0.8951 - val_loss: 0.5918 - val_acc: 0.8306






==================================================================================================


/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.
  if sys.path[0] == '':
/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`
  if sys.path[0] == '':

Epoch 1/50
390/390 [==============================] - 45s 116ms/step - loss: 1.6585 - acc: 0.4038 - val_loss: 1.3898 - val_acc: 0.4968
Epoch 2/50
390/390 [==============================] - 41s 105ms/step - loss: 1.2591 - acc: 0.5511 - val_loss: 1.1982 - val_acc: 0.5774
Epoch 3/50
390/390 [==============================] - 41s 104ms/step - loss: 1.1163 - acc: 0.6063 - val_loss: 1.0436 - val_acc: 0.6326
Epoch 4/50
390/390 [==============================] - 40s 104ms/step - loss: 1.0118 - acc: 0.6436 - val_loss: 0.9268 - val_acc: 0.6734
Epoch 5/50
390/390 [==============================] - 40s 103ms/step - loss: 0.9457 - acc: 0.6662 - val_loss: 0.8772 - val_acc: 0.6867
Epoch 6/50
390/390 [==============================] - 41s 104ms/step - loss: 0.8913 - acc: 0.6874 - val_loss: 0.8498 - val_acc: 0.6989
Epoch 7/50
390/390 [==============================] - 40s 103ms/step - loss: 0.8541 - acc: 0.7011 - val_loss: 0.7816 - val_acc: 0.7224
Epoch 8/50
390/390 [==============================] - 41s 104ms/step - loss: 0.8205 - acc: 0.7126 - val_loss: 0.7693 - val_acc: 0.7290
Epoch 9/50
390/390 [==============================] - 40s 103ms/step - loss: 0.7854 - acc: 0.7254 - val_loss: 0.7302 - val_acc: 0.7434
Epoch 10/50
390/390 [==============================] - 40s 103ms/step - loss: 0.7653 - acc: 0.7306 - val_loss: 0.7652 - val_acc: 0.7363
Epoch 11/50
390/390 [==============================] - 40s 104ms/step - loss: 0.7442 - acc: 0.7399 - val_loss: 0.7116 - val_acc: 0.7517
Epoch 12/50
390/390 [==============================] - 40s 104ms/step - loss: 0.7307 - acc: 0.7457 - val_loss: 0.7139 - val_acc: 0.7516
Epoch 13/50
390/390 [==============================] - 40s 103ms/step - loss: 0.7097 - acc: 0.7521 - val_loss: 0.6808 - val_acc: 0.7617
Epoch 14/50
390/390 [==============================] - 40s 103ms/step - loss: 0.6956 - acc: 0.7567 - val_loss: 0.6576 - val_acc: 0.7715
Epoch 15/50
390/390 [==============================] - 40s 103ms/step - loss: 0.6822 - acc: 0.7611 - val_loss: 0.6632 - val_acc: 0.7695
Epoch 16/50
390/390 [==============================] - 40s 103ms/step - loss: 0.6667 - acc: 0.7649 - val_loss: 0.6541 - val_acc: 0.7749
Epoch 17/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6602 - acc: 0.7686 - val_loss: 0.6513 - val_acc: 0.7752
Epoch 18/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6406 - acc: 0.7757 - val_loss: 0.6393 - val_acc: 0.7798
Epoch 19/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6378 - acc: 0.7769 - val_loss: 0.6419 - val_acc: 0.7768
Epoch 20/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6272 - acc: 0.7798 - val_loss: 0.6430 - val_acc: 0.7751
Epoch 21/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6200 - acc: 0.7826 - val_loss: 0.6281 - val_acc: 0.7836
Epoch 22/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6136 - acc: 0.7847 - val_loss: 0.6171 - val_acc: 0.7912
Epoch 23/50
390/390 [==============================] - 40s 102ms/step - loss: 0.6051 - acc: 0.7890 - val_loss: 0.6182 - val_acc: 0.7865
Epoch 24/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5988 - acc: 0.7895 - val_loss: 0.6019 - val_acc: 0.7922
Epoch 25/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5922 - acc: 0.7910 - val_loss: 0.6181 - val_acc: 0.7876
Epoch 26/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5830 - acc: 0.7961 - val_loss: 0.6066 - val_acc: 0.7937
Epoch 27/50
390/390 [==============================] - 40s 102ms/step - loss: 0.5800 - acc: 0.7972 - val_loss: 0.5913 - val_acc: 0.7981
Epoch 28/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5738 - acc: 0.7965 - val_loss: 0.5875 - val_acc: 0.7989
Epoch 29/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5703 - acc: 0.8009 - val_loss: 0.5979 - val_acc: 0.7968
Epoch 30/50
390/390 [==============================] - 41s 105ms/step - loss: 0.5530 - acc: 0.8051 - val_loss: 0.6022 - val_acc: 0.7923
Epoch 31/50
390/390 [==============================] - 41s 105ms/step - loss: 0.5607 - acc: 0.8043 - val_loss: 0.5951 - val_acc: 0.7985
Epoch 32/50
390/390 [==============================] - 41s 105ms/step - loss: 0.5490 - acc: 0.8077 - val_loss: 0.6599 - val_acc: 0.7766
Epoch 33/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5464 - acc: 0.8073 - val_loss: 0.5745 - val_acc: 0.8012
Epoch 34/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5428 - acc: 0.8089 - val_loss: 0.5696 - val_acc: 0.8047
Epoch 35/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5342 - acc: 0.8145 - val_loss: 0.5794 - val_acc: 0.8025
Epoch 36/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5347 - acc: 0.8126 - val_loss: 0.5780 - val_acc: 0.8016
Epoch 37/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5342 - acc: 0.8128 - val_loss: 0.5813 - val_acc: 0.8016
Epoch 38/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5255 - acc: 0.8144 - val_loss: 0.5875 - val_acc: 0.8027
Epoch 39/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5201 - acc: 0.8179 - val_loss: 0.5729 - val_acc: 0.8039
Epoch 40/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5204 - acc: 0.8176 - val_loss: 0.5950 - val_acc: 0.8035
Epoch 41/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5132 - acc: 0.8197 - val_loss: 0.5758 - val_acc: 0.8040
Epoch 42/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5099 - acc: 0.8195 - val_loss: 0.5753 - val_acc: 0.8031
Epoch 43/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5056 - acc: 0.8221 - val_loss: 0.5684 - val_acc: 0.8077
Epoch 44/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5052 - acc: 0.8223 - val_loss: 0.5654 - val_acc: 0.8102
Epoch 45/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5038 - acc: 0.8221 - val_loss: 0.5534 - val_acc: 0.8134
Epoch 46/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5003 - acc: 0.8238 - val_loss: 0.5850 - val_acc: 0.8026
Epoch 47/50
390/390 [==============================] - 40s 103ms/step - loss: 0.4992 - acc: 0.8226 - val_loss: 0.5757 - val_acc: 0.8048
Epoch 48/50
390/390 [==============================] - 41s 104ms/step - loss: 0.4987 - acc: 0.8247 - val_loss: 0.5539 - val_acc: 0.8154
Epoch 49/50
390/390 [==============================] - 40s 103ms/step - loss: 0.4875 - acc: 0.8289 - val_loss: 0.5599 - val_acc: 0.8123
Epoch 50/50
390/390 [==============================] - 40s 103ms/step - loss: 0.4948 - acc: 0.8268 - val_loss: 0.5541 - val_acc: 0.8126
Model took 2021.85 seconds to train





model = Sequential()
#model.add(Convolution2D(48, 3, 3, border_mode='same', input_shape=(32, 32, 3)))
model.add(SeparableConv2D(48, (3,3), depth_multiplier=1, activation='relu',input_shape=(32, 32, 3))) 
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(SeparableConv2D(64, (3,3), depth_multiplier=1, activation='relu')) #30x30
#model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(SeparableConv2D(96, (3,3), depth_multiplier=1, activation='relu')) #28x28
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(SeparableConv2D(128, (3,3), depth_multiplier=1, activation='relu')) #13x13
model.add(BatchNormalization())
#model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(SeparableConv2D(186, (3,3), depth_multiplier=1, activation='relu')) #11x11
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(SeparableConv2D(236, (3,3), depth_multiplier=1, activation='relu')) #4x4
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(SeparableConv2D(10, 1, depth_multiplier=1, activation='relu'))

model.add(Flatten())
model.add(Activation('softmax'))

#model.add(Dense(256))#512
#model.add(Dropout(0.5))

#model.add(Dense(10))#256
#model.add(Activation('relu'))
#model.add(Dropout(0.5))
#model.add(Dense(num_classes, activation='softmax'))
# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])


Accuracy on test data is: 81.26

=====================================================================================================
/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.
  if sys.path[0] == '':
/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., verbose=1, steps_per_epoch=390, epochs=50)`
  if sys.path[0] == '':

Epoch 1/50
390/390 [==============================] - 45s 114ms/step - loss: 1.6172 - acc: 0.4220 - val_loss: 1.3198 - val_acc: 0.5266
Epoch 2/50
390/390 [==============================] - 41s 105ms/step - loss: 1.2130 - acc: 0.5705 - val_loss: 1.1498 - val_acc: 0.5966
Epoch 3/50
390/390 [==============================] - 41s 105ms/step - loss: 1.0782 - acc: 0.6182 - val_loss: 1.0515 - val_acc: 0.6302
Epoch 4/50
390/390 [==============================] - 41s 104ms/step - loss: 0.9903 - acc: 0.6492 - val_loss: 0.9431 - val_acc: 0.6706
Epoch 5/50
390/390 [==============================] - 41s 104ms/step - loss: 0.9306 - acc: 0.6726 - val_loss: 0.9073 - val_acc: 0.6848
Epoch 6/50
390/390 [==============================] - 41s 105ms/step - loss: 0.8902 - acc: 0.6861 - val_loss: 0.8416 - val_acc: 0.7012
Epoch 7/50
390/390 [==============================] - 41s 105ms/step - loss: 0.8525 - acc: 0.7005 - val_loss: 0.8020 - val_acc: 0.7178
Epoch 8/50
390/390 [==============================] - 41s 104ms/step - loss: 0.8184 - acc: 0.7130 - val_loss: 0.8302 - val_acc: 0.7074
Epoch 9/50
390/390 [==============================] - 41s 104ms/step - loss: 0.7943 - acc: 0.7217 - val_loss: 0.8605 - val_acc: 0.7101
Epoch 10/50
390/390 [==============================] - 41s 105ms/step - loss: 0.7736 - acc: 0.7301 - val_loss: 0.7888 - val_acc: 0.7266
Epoch 11/50
390/390 [==============================] - 41s 105ms/step - loss: 0.7547 - acc: 0.7368 - val_loss: 0.7344 - val_acc: 0.7447
Epoch 12/50
390/390 [==============================] - 41s 105ms/step - loss: 0.7361 - acc: 0.7415 - val_loss: 0.7166 - val_acc: 0.7475
Epoch 13/50
390/390 [==============================] - 40s 104ms/step - loss: 0.7189 - acc: 0.7506 - val_loss: 0.8476 - val_acc: 0.7040
Epoch 14/50
390/390 [==============================] - 40s 104ms/step - loss: 0.7043 - acc: 0.7532 - val_loss: 0.8083 - val_acc: 0.7183
Epoch 15/50
390/390 [==============================] - 40s 104ms/step - loss: 0.6903 - acc: 0.7578 - val_loss: 0.7554 - val_acc: 0.7426
Epoch 16/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6780 - acc: 0.7645 - val_loss: 0.6908 - val_acc: 0.7579
Epoch 17/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6693 - acc: 0.7665 - val_loss: 0.7310 - val_acc: 0.7479
Epoch 18/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6578 - acc: 0.7690 - val_loss: 0.7387 - val_acc: 0.7428
Epoch 19/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6468 - acc: 0.7742 - val_loss: 0.6667 - val_acc: 0.7674
Epoch 20/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6395 - acc: 0.7754 - val_loss: 0.6554 - val_acc: 0.7711
Epoch 21/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6320 - acc: 0.7796 - val_loss: 0.7219 - val_acc: 0.7486
Epoch 22/50
390/390 [==============================] - 40s 104ms/step - loss: 0.6224 - acc: 0.7832 - val_loss: 0.6342 - val_acc: 0.7796
Epoch 23/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6185 - acc: 0.7837 - val_loss: 0.6670 - val_acc: 0.7733
Epoch 24/50
390/390 [==============================] - 40s 104ms/step - loss: 0.6078 - acc: 0.7868 - val_loss: 0.6519 - val_acc: 0.7764
Epoch 25/50
390/390 [==============================] - 41s 104ms/step - loss: 0.6086 - acc: 0.7888 - val_loss: 0.6927 - val_acc: 0.7655
Epoch 26/50
390/390 [==============================] - 40s 104ms/step - loss: 0.6005 - acc: 0.7898 - val_loss: 0.6224 - val_acc: 0.7879
Epoch 27/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5939 - acc: 0.7903 - val_loss: 0.6072 - val_acc: 0.7881
Epoch 28/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5797 - acc: 0.7975 - val_loss: 0.6734 - val_acc: 0.7670
Epoch 29/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5809 - acc: 0.7963 - val_loss: 0.6295 - val_acc: 0.7840
Epoch 30/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5701 - acc: 0.8012 - val_loss: 0.5948 - val_acc: 0.7985
Epoch 31/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5718 - acc: 0.7981 - val_loss: 0.6055 - val_acc: 0.7854
Epoch 32/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5613 - acc: 0.8019 - val_loss: 0.6187 - val_acc: 0.7854
Epoch 33/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5656 - acc: 0.8020 - val_loss: 0.6340 - val_acc: 0.7794
Epoch 34/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5533 - acc: 0.8057 - val_loss: 0.6105 - val_acc: 0.7895
Epoch 35/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5541 - acc: 0.8057 - val_loss: 0.5989 - val_acc: 0.7945
Epoch 36/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5417 - acc: 0.8090 - val_loss: 0.6097 - val_acc: 0.7894
Epoch 37/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5441 - acc: 0.8091 - val_loss: 0.6146 - val_acc: 0.7890
Epoch 38/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5341 - acc: 0.8125 - val_loss: 0.6003 - val_acc: 0.7921
Epoch 39/50
390/390 [==============================] - 41s 104ms/step - loss: 0.5348 - acc: 0.8132 - val_loss: 0.5976 - val_acc: 0.7893
Epoch 40/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5269 - acc: 0.8150 - val_loss: 0.5897 - val_acc: 0.7973
Epoch 41/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5301 - acc: 0.8143 - val_loss: 0.5854 - val_acc: 0.7983
Epoch 42/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5303 - acc: 0.8139 - val_loss: 0.5838 - val_acc: 0.8000
Epoch 43/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5185 - acc: 0.8167 - val_loss: 0.5705 - val_acc: 0.8058
Epoch 44/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5176 - acc: 0.8178 - val_loss: 0.5773 - val_acc: 0.7986
Epoch 45/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5121 - acc: 0.8190 - val_loss: 0.5878 - val_acc: 0.8008
Epoch 46/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5087 - acc: 0.8206 - val_loss: 0.5644 - val_acc: 0.8077
Epoch 47/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5103 - acc: 0.8202 - val_loss: 0.5763 - val_acc: 0.8067
Epoch 48/50
390/390 [==============================] - 40s 103ms/step - loss: 0.5087 - acc: 0.8211 - val_loss: 0.5672 - val_acc: 0.8099
Epoch 49/50
390/390 [==============================] - 40s 104ms/step - loss: 0.5060 - acc: 0.8231 - val_loss: 0.5881 - val_acc: 0.8017
Epoch 50/50
390/390 [==============================] - 40s 104ms/step - loss: 0.4979 - acc: 0.8251 - val_loss: 0.5506 - val_acc: 0.8110
Model took 2032.31 seconds to train

Accuracy on test data is: 81.10


# Define the model
model = Sequential()
#model.add(Convolution2D(48, 3, 3, border_mode='same', input_shape=(32, 32, 3)))
model.add(SeparableConv2D(48, (3,3), depth_multiplier=1, activation='relu',input_shape=(32, 32, 3))) 
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(SeparableConv2D(64, (3,3), depth_multiplier=1, activation='relu')) #30x30
#model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(SeparableConv2D(96, (3,3), depth_multiplier=1, activation='relu')) #28x28
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(SeparableConv2D(128, (3,3), depth_multiplier=1, activation='relu')) #13x13
model.add(BatchNormalization())
#model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(SeparableConv2D(186, (3,3), depth_multiplier=1, activation='relu')) #11x11
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(SeparableConv2D(232, (3,3), depth_multiplier=1, activation='relu')) #4x4
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(SeparableConv2D(10, 1, depth_multiplier=1, activation='relu'))

model.add(Flatten())
model.add(Activation('softmax'))

#model.add(Dense(256))#512
#model.add(Dropout(0.5))

#model.add(Dense(10))#256
#model.add(Activation('relu'))
#model.add(Dropout(0.5))
#model.add(Dense(num_classes, activation='softmax'))
# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

